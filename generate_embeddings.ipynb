{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index-readers-file 0.5.6 requires pandas<3,>=2.0.0, but you have pandas 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install dependencies if not already installed\n",
        "!pip install -qU pandas llama-index-embeddings-gemini google-genai tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import logging\n",
        "logging.getLogger('llama_index').setLevel(logging.ERROR)\n",
        "\n",
        "import pandas as pd\n",
        "import ast\n",
        "import os\n",
        "import time\n",
        "import getpass\n",
        "from tqdm import tqdm\n",
        "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
        "from google.genai.types import EmbedContentConfig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup Google API Key\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading movies_metadata.csv...\n",
            "Loading credits.csv...\n",
            "Merging data...\n",
            "Total raw rows: 45538\n"
          ]
        }
      ],
      "source": [
        "def load_and_process_data(data_path):\n",
        "    print('Loading movies_metadata.csv...')\n",
        "    movies = pd.read_csv(os.path.join(data_path, \"movies_metadata.csv\"), low_memory=False)\n",
        "    # Clean IDs\n",
        "    movies = movies[pd.to_numeric(movies['id'], errors='coerce').notnull()]\n",
        "    movies['id'] = movies['id'].astype(int)\n",
        "    \n",
        "    print('Loading credits.csv...')\n",
        "    credits = pd.read_csv(os.path.join(data_path, \"credits.csv\"))\n",
        "    credits['id'] = credits['id'].astype(int)\n",
        "    \n",
        "    print('Merging data...')\n",
        "    data = movies.merge(credits, on='id')\n",
        "    return data\n",
        "\n",
        "data_path = \"./data\"\n",
        "df_raw = load_and_process_data(data_path)\n",
        "print(f\"Total raw rows: {len(df_raw)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing columns (this may take a moment)...\n"
          ]
        }
      ],
      "source": [
        "def parse_json_col(x, key):\n",
        "    try:\n",
        "        items = ast.literal_eval(x)\n",
        "        if isinstance(items, list):\n",
        "            return [i[key] for i in items if isinstance(i, dict) and key in i]\n",
        "        return []\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "print('Preprocessing columns (this may take a moment)...')\n",
        "# Process necessary columns\n",
        "df_raw['genres_list'] = df_raw['genres'].apply(lambda x: parse_json_col(x, 'name'))\n",
        "df_raw['cast_list'] = df_raw['cast'].apply(lambda x: parse_json_col(x, 'name')[:5]) # Top 5 cast\n",
        "df_raw['languages_list'] = df_raw['spoken_languages'].apply(lambda x: parse_json_col(x, 'name'))\n",
        "df_raw['fullplot'] = df_raw['overview'].fillna('')\n",
        "df_raw['title'] = df_raw['title'].fillna('')\n",
        "df_raw['rating'] = pd.to_numeric(df_raw['vote_average'], errors='coerce').fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined text created.\n",
            "Sample:\n",
            "Title: Toy Story\n",
            "Plot: Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\n",
            "Cast: Tom Hanks, Tim Allen, Don Rickles, Jim Varney, Wallace Shawn\n",
            "Genres: Animation, Comedy, Family\n",
            "Languages: English\n",
            "Rating: 7.7\n"
          ]
        }
      ],
      "source": [
        "# Create the text to embed\n",
        "def create_combined_text(row):\n",
        "    return (\n",
        "        f\"Title: {row['title']}\\n\"\n",
        "        f\"Plot: {row['fullplot']}\\n\"\n",
        "        f\"Cast: {', '.join(row['cast_list'])}\\n\"\n",
        "        f\"Genres: {', '.join(row['genres_list'])}\\n\"\n",
        "        f\"Languages: {', '.join(row['languages_list'])}\\n\"\n",
        "        f\"Rating: {row['rating']}\"\n",
        "    )\n",
        "\n",
        "df_raw['combined_text'] = df_raw.apply(create_combined_text, axis=1)\n",
        "print(\"Combined text created.\")\n",
        "print(\"Sample:\")\n",
        "print(df_raw['combined_text'].iloc[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding successful. Dimension: 3072\n"
          ]
        }
      ],
      "source": [
        "# Initialize Google GenAI Embedding\n",
        "model_name = \"gemini-embedding-001\"\n",
        "embed_model = GoogleGenAIEmbedding(\n",
        "    model_name=model_name,\n",
        "    embedding_config=EmbedContentConfig(output_dimensionality=3072)\n",
        ")\n",
        "# Testing with one example\n",
        "try:\n",
        "    test_embed = embed_model.get_text_embedding(\"Hello World\")\n",
        "    print(f\"Embedding successful. Dimension: {len(test_embed)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing embedding model: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running sanity check on top 3 rows...\n",
            "Successfully generated 3 embeddings.\n",
            "Embedding dimensions: 3072\n",
            "First 5 values of the first embedding: [-0.027750747, -0.0032961427, 0.00066539174, -0.062563874, -0.009756115]\n",
            "Sanity check PASSED. You can proceed to the full batch run below.\n"
          ]
        }
      ],
      "source": [
        "# --- SANITY CHECK ---\n",
        "# Let's verify embeddings working on the actual data before running the full job\n",
        "print(\"Running sanity check on top 3 rows...\")\n",
        "sample_texts = df_raw['combined_text'].head(3).tolist()\n",
        "try:\n",
        "    sample_embeddings = embed_model.get_text_embedding_batch(sample_texts)\n",
        "    print(f\"Successfully generated {len(sample_embeddings)} embeddings.\")\n",
        "    print(f\"Embedding dimensions: {len(sample_embeddings[0])}\")\n",
        "    print(\"First 5 values of the first embedding:\", sample_embeddings[0][:5])\n",
        "    print(\"Sanity check PASSED. You can proceed to the full batch run below.\")\n",
        "except Exception as e:\n",
        "    print(f\"Sanity check FAILED: {e}\")\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting embedding generation for 45538 items in 911 batches...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 911/911 [1:08:42<00:00,  4.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished. Successful embeddings: 45538 / 45538\n"
          ]
        }
      ],
      "source": [
        "# Generate Embeddings with Batching\n",
        "import math\n",
        "\n",
        "# Configuration\n",
        "BATCH_SIZE = 50 # Safe batch size\n",
        "SAVE_INTERVAL = 1000 # Save every 1000 rows to a temp file\n",
        "OUTPUT_FILE = os.path.join(data_path, \"movies_with_embeddings.csv\")\n",
        "\n",
        "# work on a copy\n",
        "df_processed = df_raw.copy()\n",
        "embeddings = []\n",
        "texts = df_processed['combined_text'].tolist()\n",
        "total_batches = math.ceil(len(texts) / BATCH_SIZE)\n",
        "\n",
        "print(f\"Starting embedding generation for {len(texts)} items in {total_batches} batches...\")\n",
        "\n",
        "for i in tqdm(range(0, len(texts), BATCH_SIZE)):\n",
        "    batch_texts = texts[i : i + BATCH_SIZE]\n",
        "    try:\n",
        "        # LlamaIndex helper for batch embeddings\n",
        "        batch_embeddings = embed_model.get_text_embedding_batch(batch_texts)\n",
        "        embeddings.extend(batch_embeddings)\n",
        "        \n",
        "        # Rate limit handling (Free tier is 15 RPM, we are doing batches)\n",
        "        # A batch of 50 counts as ? If it counts as 1 request, we can go faster.\n",
        "        # If it counts as 50 requests, we must sleep.\n",
        "        # Usually batch endpoints count as 1 HTTP request but quota might be token based.\n",
        "        # We'll sleep a little just to be safe and avoid 429s.\n",
        "        time.sleep(2) \n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error at batch {i}: {e}\")\n",
        "        # Append None or zeros? Better to handle gracefully.\n",
        "        # For now, we'll try to append empty lists to keep alignment\n",
        "        embeddings.extend([[] for _ in range(len(batch_texts))])\n",
        "        time.sleep(10) # Longer sleep on error\n",
        "\n",
        "# Add embeddings to dataframe\n",
        "df_processed['embedding'] = embeddings\n",
        "\n",
        "# Filter out failed embeddings\n",
        "df_final = df_processed[df_processed['embedding'].apply(len) > 0]\n",
        "print(f\"Finished. Successful embeddings: {len(df_final)} / {len(df_processed)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving to ./data/movies_with_embeddings.csv...\n"
          ]
        }
      ],
      "source": [
        "# Save to CSV\n",
        "print(f\"Saving to {OUTPUT_FILE}...\")\n",
        "df_final.to_csv(OUTPUT_FILE, index=False)\n",
        "print(\"Done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llamaindex",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
